# BERTviz Explorer

An interactive visualization tool to explore **BERT's attention mechanisms** in a sentence. This tool helps researchers, ML engineers, and NLP enthusiasts understand how BERT focuses on different tokens across layers during prediction.

![BERTviz Explorer Demo](./readme/image.png)

---

## ğŸš€ Features

- Visualizes attention across BERT's layers and heads
- Interactive sentence input and real-time heatmap generation
- Token-level attention insights
- Simple UI for navigating between attention layers

---

## ğŸ§  How It Works

Enter any sentence, and BERTViz will:

1. Tokenize the input
2. Feed it into a pretrained BERT model
3. Extract attention weights
4. Render layer-wise heatmaps showing token-to-token attention

---

## ğŸ“¦ Installation

Clone the repo and install dependencies:

```bash
git clone https://github.com/Reachariramanan/BERTViz.git
cd BERTViz
pip install -r requirements.txt
````

---

## ğŸ–¥ï¸ Run the App

```bash
streamlit run app.py
```

This will open the BERTviz Explorer in your browser. Input any sentence and click **Visualize**.

---

## ğŸ“ Example

**Input:**
`BERT helps visualize attention`

**Output:**
Layer-wise attention heatmaps showing how each word attends to others across the network layers.

---

## ğŸ“ Folder Structure

```
BERTViz/
â”œâ”€â”€ app.py
â”œâ”€â”€ readme/
â”‚   â””â”€â”€ image.png
â”œâ”€â”€ components/
â”œâ”€â”€ models/
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ¤ Contributing

Contributions are welcome! Feel free to open issues or pull requests.

---

## ğŸ“„ License

This project is licensed under the [MIT License](LICENSE).

```
